{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the notebook\n",
    "* There were three dataframes that were created during the transformation process <br>\n",
    "viz. trans_train_df(transformed train data),trans_merch_df(transformed merchant data),trans_hist_df(transformed historical data)\n",
    "* Dropped a few duplicate columns and unwanted columns with low correlation with the target variable.\n",
    "* The total number of columns obtained after performing the above operations = 589\n",
    "* [Action plan of imputation](#action_plan_for_imputation)\n",
    "* [Missing Values percentage and analysis](#percentage_of_missing_values)\n",
    "* [Initial dropping of features](#initial_dropping_of_features)\n",
    "* [Modification_in_imputation_strategy](#modification_in_imputation_strategy)\n",
    "* [Median,Mode based imputation](#median_mode_based_imputation)\n",
    "* [Model based imputation](#model_based_imputation)\n",
    "* [Mix of median,mode and model based imputation](#mixed_imputation)\n",
    "* [Comparing_performances](#comparing_performances)\n",
    "* [Final Analysis](#final_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Y4R2gbxuz_jq",
    "outputId": "47824608-4a6a-496b-fb58-ecf6a6efcfb0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8AAbGBsO8F_"
   },
   "outputs": [],
   "source": [
    "## Importing all the necessary Imputers and Tree based models\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "rbjHJ-lI0Gzj",
    "outputId": "f2064f1c-e176-41f3-ae23-bc9aa1c660f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsFahn8ZO2hX"
   },
   "outputs": [],
   "source": [
    "## Creating a scoring function for RMSE as this is the metric used in the competition\n",
    "def root_mean_squared_error(model,X,y_true):\n",
    "  y_pred = model.predict(X)\n",
    "  return np.sqrt(mse(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bsgNjmQl0Yfo",
    "outputId": "bbf2b84c-e67b-4ee0-e5ad-c77a597d4c99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 600)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importing all the required dataframes\n",
    "trans_train_df = pickle.load(open('gdrive/My Drive/ColabNotebooks/trans_train_df.pkl','rb'))\n",
    "trans_merch_df = pickle.load(open('gdrive/My Drive/ColabNotebooks/trans_merch_df.pkl','rb'))\n",
    "trans_hist_df = pickle.load(open('gdrive/My Drive/ColabNotebooks/trans_hist_df.pkl','rb'))\n",
    "\n",
    "## Merging all the dataframes\n",
    "trans_df = pd.merge(trans_train_df,trans_merch_df,on='card_id',how='inner')\n",
    "trans_df = pd.merge(trans_df,trans_hist_df,on='card_id',how='inner')\n",
    "trans_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NzQbiopSCNNc",
    "outputId": "5e661adf-7e69-43c7-a0f3-47e2969a1b31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 589)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## In the process of merging \n",
    "## identified few duplicate columns\n",
    "## so dropping them.\n",
    "\n",
    "trans_df = trans_df.loc[:,~trans_df.columns.duplicated()]\n",
    "## These are some of the useless columns which \n",
    "## don't add much value to the model(identified during EDA)\n",
    "## plus needs an additional conversion into one-hot or \n",
    "## label encoding. So dropping these features as well\n",
    "\n",
    "cat_col_list = ['first_active_month','category_1_mode','category_3_mode','subsector_id_mode',\n",
    "                'merchant_category_id_mode','category_4_mode', 'most_recent_sales_range_mode',\n",
    "                'most_recent_purchases_range_mode','card_id']\n",
    "trans_df.drop(cat_col_list,axis=1,inplace=True)\n",
    "trans_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVrUJWdaCw8U"
   },
   "outputs": [],
   "source": [
    "## Replacing all infinity values by nan's\n",
    "trans_df.replace([np.inf,-np.inf],np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXWXrl5GGUfF"
   },
   "source": [
    "<a id='action_plan_for_imputation'></a>\n",
    "## 2. Action plan for imputation\n",
    "* Let's divide the features into three sets.\n",
    "* Features with more than certain threshold of missing values,let's drop them.\n",
    "* Feature with less than certain threshold of missing values, let's perform median or model based imputation.\n",
    "* For rest of the features let's do model based imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tB4_IlYZ-p4y",
    "outputId": "4d8be235-7c52-4c02-fed3-9967606975dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 588)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dividing the dataset into train and target\n",
    "X_train = trans_df.drop(['target'],axis=1)\n",
    "y_train = trans_df['target']\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvcXs1HfoKve"
   },
   "source": [
    "<a id=\"percentage_of_missing_values\"></a>\n",
    "## 3. Identifying thresholds for different imputation regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "id": "3mVQ5OL65IFt",
    "outputId": "89e3e4da-558e-40a0-e50b-57910df1a666"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_2_bin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_1_bin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  null_count\n",
       "0      feature_1         0.0\n",
       "1      feature_2         0.0\n",
       "2      feature_3         0.0\n",
       "3  feature_2_bin         0.0\n",
       "4  feature_1_bin         0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Forming a dataframe based on null counts in each of the feature\n",
    "null_count_df = (X_train.isnull().sum()*100/X_train.shape[0]).reset_index().rename(columns = {0 : 'null_count'})\n",
    "null_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "WEG_VYGX7Qj1",
    "outputId": "ab811eb8-e98f-441d-949f-c68d25d4a832"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of features vs percentage of missing values')"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plotting the number of features and percentage of missing values in them\n",
    "percentile_10 = np.percentile(null_count_df['null_count'],q=[i for i in range(0,101,10)])\n",
    "x_ticks = [i*(600/100) for i in range(0,101,10)]\n",
    "plt.plot(x_ticks,percentile_10,marker='o') \n",
    "plt.xticks(x_ticks,x_ticks)\n",
    "plt.ylabel('percentage of missing values')\n",
    "plt.xlabel('number of features')\n",
    "plt.title('Number of features vs percentage of missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KjUQm1zlsR7h"
   },
   "source": [
    "## Analysis:\n",
    "* For upto 240 features we don't have missing values.\n",
    "* Beyond that we can see a steep increase in the number of the missing values features.\n",
    "* By looking at this plot I am thinking of dividing the missing values into three regions.\n",
    "\n",
    "* Plan in first iteration\n",
    "  * No-Null values\n",
    "  * Median Imputation features with missing values greater than 0  and less than 25.\n",
    "  * Model based imputation for 25 to 66 percentile missing values.\n",
    "  * Elimination of remaining features.\n",
    "\n",
    "* Plan after third iteration \n",
    "  * After several parameter tuning and realizing the RAM and core capacities finally decided on dividing the regions on following thresholds.\n",
    "  * No-Null values.\n",
    "  * mean_imputation = 0-50\n",
    "  * model_imputation = 50-66\n",
    "  * eliminate features with more than 66% missing values.\n",
    "\n",
    "* Above thresholds were obtained from quantile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ZDUNFoZ8FUu"
   },
   "outputs": [],
   "source": [
    "nnull_impute_feat = null_count_df[(null_count_df['null_count'] == 0)]['index'].values \n",
    "mean_impute_feat = null_count_df[(null_count_df['null_count'] > 0) & (null_count_df['null_count'] <= 50)]['index'].values\n",
    "model_impute_feat = null_count_df[(null_count_df['null_count'] > 50) & (null_count_df['null_count'] <= 66)]['index'].values\n",
    "eliminate_feat = null_count_df[(null_count_df['null_count'] > 66)]['index'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GnE_2LqqyEz"
   },
   "source": [
    "<a id = 'initial_dropping_of_features'></a>\n",
    "### 3.1 Some General observations on the features to be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "colab_type": "code",
    "id": "jBg1_G5zqsr9",
    "outputId": "2324bad9-dd4d-4815-c9c0-1782b14a43fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['np_amount_min_7_9', 'np_amount_min_8_10', 'np_amount_min_9_11',\n",
       "       'np_amount_min_10_12', 'np_amount_min_11_13', 'np_amount_max_7_9',\n",
       "       'np_amount_max_8_10', 'np_amount_max_9_11', 'np_amount_max_10_12',\n",
       "       'np_amount_max_11_13', 'np_amount_mean_7_9', 'np_amount_mean_8_10',\n",
       "       'np_amount_mean_9_11', 'np_amount_mean_10_12',\n",
       "       'np_amount_mean_11_13', 'np_amount_sum_7_9', 'np_amount_sum_8_10',\n",
       "       'np_amount_sum_9_11', 'np_amount_sum_10_12', 'np_amount_sum_11_13',\n",
       "       'np_amount_std_6_8', 'np_amount_std_7_9', 'np_amount_std_8_10',\n",
       "       'np_amount_std_9_11', 'np_amount_std_10_12', 'np_amount_std_11_13',\n",
       "       'np_amount_min_12', 'np_amount_min_11', 'np_amount_min_10',\n",
       "       'np_amount_min_13', 'np_amount_max_12', 'np_amount_max_11',\n",
       "       'np_amount_max_10', 'np_amount_max_13', 'np_amount_mean_12',\n",
       "       'np_amount_mean_11', 'np_amount_mean_10', 'np_amount_mean_13',\n",
       "       'np_amount_sum_12', 'np_amount_sum_11', 'np_amount_sum_10',\n",
       "       'np_amount_sum_13', 'np_amount_std_12', 'np_amount_std_11',\n",
       "       'np_amount_std_10', 'np_amount_std_9', 'np_amount_std_13',\n",
       "       'np_amount_min_8_9', 'np_amount_min_9_10', 'np_amount_min_10_11',\n",
       "       'np_amount_min_11_12', 'np_amount_max_8_9', 'np_amount_max_9_10',\n",
       "       'np_amount_max_10_11', 'np_amount_max_11_12', 'np_amount_mean_8_9',\n",
       "       'np_amount_mean_9_10', 'np_amount_mean_10_11',\n",
       "       'np_amount_mean_11_12', 'np_amount_sum_8_9', 'np_amount_sum_9_10',\n",
       "       'np_amount_sum_10_11', 'np_amount_sum_11_12', 'np_amount_std_7_8',\n",
       "       'np_amount_std_8_9', 'np_amount_std_9_10', 'np_amount_std_10_11',\n",
       "       'np_amount_std_11_12', 'install_5_min', 'install_5_max',\n",
       "       'install_5_mean', 'install_5_sum', 'install_5_std',\n",
       "       'install_3_std', 'install_0_min', 'install_0_max',\n",
       "       'install_0_mean', 'install_0_sum', 'install_0_std',\n",
       "       'install_-1_min', 'install_-1_max', 'install_-1_mean',\n",
       "       'install_-1_sum', 'install_-1_std', 'install_4_min',\n",
       "       'install_4_max', 'install_4_mean', 'install_4_sum',\n",
       "       'install_4_std', 'install_2_std', 'install_10_min',\n",
       "       'install_10_max', 'install_10_mean', 'install_10_sum',\n",
       "       'install_10_std', 'install_6_min', 'install_6_max',\n",
       "       'install_6_mean', 'install_6_sum', 'install_6_std',\n",
       "       'install_7_min', 'install_7_max', 'install_7_mean',\n",
       "       'install_7_sum', 'install_7_std', 'install_12_min',\n",
       "       'install_12_max', 'install_12_mean', 'install_12_sum',\n",
       "       'install_12_std', 'install_8_min', 'install_8_max',\n",
       "       'install_8_mean', 'install_8_sum', 'install_8_std',\n",
       "       'install_9_min', 'install_9_max', 'install_9_mean',\n",
       "       'install_9_sum', 'install_9_std', 'install_11_min',\n",
       "       'install_11_max', 'install_11_mean', 'install_11_sum',\n",
       "       'install_11_std', 'install_999_min', 'install_999_max',\n",
       "       'install_999_mean', 'install_999_sum', 'install_999_std'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminate_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2estXD5AD0X4"
   },
   "source": [
    "* As suggested by Raddar the most recent transactions are more important than the previous ones. <br>\n",
    "* Even with the features in above section we can see that the purchase amount ratios and purchase amount aggregate functions for months beyond 7 and 8 contain a lot of null values.<br>\n",
    "* So we are going to drop these features.\n",
    "* Also we are going to look at which installment features are retained for model imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "wRCXXN3FBMWx",
    "outputId": "613672dd-b851-47e6-96ab-8999c51a5049"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['install_1_min',\n",
       " 'install_1_sum',\n",
       " 'install_1_max',\n",
       " 'install_1_std',\n",
       " 'install_1_mean',\n",
       " 'install_2_min',\n",
       " 'install_2_sum',\n",
       " 'install_2_max',\n",
       " 'install_2_mean',\n",
       " 'install_3_min',\n",
       " 'install_3_sum',\n",
       " 'install_3_max',\n",
       " 'install_3_mean']"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "install = [i for i in range(0,13)]\n",
    "install = install + [-1,999]\n",
    "\n",
    "aggr_funcs = ['min','sum','max','std','mean']\n",
    "install_feat=[]\n",
    "for month in install:\n",
    "  for func in aggr_funcs:\n",
    "    install_feat.append('install_' + str(month) + \"_\" + str(func))\n",
    "\n",
    "nnull_install_feat = [feat for feat in install_feat if feat not in eliminate_feat]\n",
    "nnull_install_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFKwxSt7Femu"
   },
   "source": [
    "* Installment features for a value beyond 3 contain a lot of null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-FplIq0G3Am"
   },
   "source": [
    "<a id = \"modification_in_imputation_strategy\"></a>\n",
    "## 3.2 Some modification in the plan\n",
    "* After studying a bit about imputation.\n",
    "* Let's try out a few strategies of imputing the data\n",
    "  * imputing all data by median and mode imputation.(excluding the eliminate_features)\n",
    "  * imputing all data by model based imputation.(excluding the eliminate_features)\n",
    "  * imputing based on percentile of missing values.(a mix of both median and model based imputation,excluding eliminate features)\n",
    "  * If time permits doing all of the above including eliminate features.(realized that we face RAM crash issues)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "nf-aW5rVG1Fx",
    "outputId": "03d43f89-3f88-433f-8585-277966ea85b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of not null features :  277\n",
      "Length of mean imputation features :  136\n",
      "Length of model imputation features :  45\n",
      "Length of initial feature set to work with :  458\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of not null features : \",len(nnull_impute_feat))\n",
    "print(\"Length of mean imputation features : \",len(mean_impute_feat))\n",
    "print(\"Length of model imputation features : \",len(model_impute_feat))\n",
    "print(\"Length of initial feature set to work with : \",len(nnull_impute_feat) + len(mean_impute_feat) + len(model_impute_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cCNQ6ou9C4lY"
   },
   "outputs": [],
   "source": [
    "impute_features = list(nnull_impute_feat) + list(mean_impute_feat) + list(model_impute_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jnWRoxt_wTmc",
    "outputId": "3a584b2b-8bcf-44bc-d06c-1f47b21ac4e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 458)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features = X_train[impute_features].copy()\n",
    "y_target = y_train.copy()\n",
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3Sxl1tMiEhLY",
    "outputId": "50236aff-8ca5-44ef-f47a-30c2583049d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('int64'), dtype('float64'), dtype('bool'), dtype('float32')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.dtypes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4XCixkmJNeMz"
   },
   "source": [
    "<a id=\"median_mode_based_imputation\"></a>\n",
    "## 4. Median based imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "33D3PEGTuzHf"
   },
   "source": [
    "### 4.1 Function for Median based imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3h6IT5FQwmH-"
   },
   "outputs": [],
   "source": [
    "def categoricalImputer(X_features):\n",
    "  \"\"\"\n",
    "    Imputation of categorical features by most_frequent category\n",
    "  \"\"\"\n",
    "  cat_imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "  return pd.DataFrame(cat_imputer.fit_transform(X_features),columns = X_features.columns)\n",
    "  \n",
    "def numericalImputer(X_features):\n",
    "  \"\"\"\n",
    "    Imputation of numerical features by median value\n",
    "  \"\"\"\n",
    "  num_imputer = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "  return pd.DataFrame(num_imputer.fit_transform(X_features),columns = X_features.columns)\n",
    "\n",
    "def simpleImputerForAllCategories(X_features):\n",
    "  \n",
    "  \"\"\"\n",
    "    Performs median and mode based imputation for numerical and categorical features.\n",
    "  \"\"\"\n",
    "  cat_cols = X_features.select_dtypes('int64').columns\n",
    "  num_cols_1 = X_features.select_dtypes('float32').columns\n",
    "  num_cols_2 = X_features.select_dtypes('float64').columns\n",
    "  bool_cols = X_features.select_dtypes('bool').columns\n",
    "\n",
    "  ## There is no imputer for boolean type of data \n",
    "  ## So converting it into 0's and 1's\n",
    "  print(\"Converting boolean columns to 1's and 0's(int type)...\")\n",
    "  for col in bool_cols:\n",
    "    X_features[col] = X_features[col].apply(lambda x : 1 if True else 0)\n",
    "\n",
    "  cols_list = [cat_cols,num_cols_1,num_cols_2,bool_cols]\n",
    "  imputed_features = []\n",
    "  for cols in cols_list:\n",
    "    if len(cols) > 0:\n",
    "      if X_features[cols].dtypes.unique()[0] == 'int':\n",
    "        print(\"Imputing for categorical variables...\")\n",
    "        imputed_features.append(categoricalImputer(X_features[cols]))\n",
    "      else:\n",
    "        print(\"Imputing for numerical variables...\")\n",
    "        imputed_features.append(numericalImputer(X_features[cols]))\n",
    "    \n",
    "  print(\"Features imputed...\")\n",
    "  return pd.concat(imputed_features,axis=1)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "iJ_WlVclBjWI",
    "outputId": "2d9380e7-a764-4f8c-ee6d-beee8934f908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting boolean columns to 1's and 0's(int type)...\n",
      "Imputing for categorical variables...\n",
      "Imputing for categorical variables...\n",
      "Features imputed...\n",
      "(201917, 458)\n"
     ]
    }
   ],
   "source": [
    "## performing imputation and storing the pickle file\n",
    "imputed_df = simpleImputerForAllCategories(X_features)\n",
    "print(imputed_df.shape)\n",
    "pickle.dump(imputed_df,open('gdrive/My Drive/ColabNotebooks/simple_imputed_df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mtO80elueLzd"
   },
   "outputs": [],
   "source": [
    "## retrieving the imputed file\n",
    "mean_imputed_df = pickle.load(open('gdrive/My Drive/ColabNotebooks/simple_imputed_df.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aoE0FIQqu7wV"
   },
   "source": [
    "### 4.2 Estimating the performance of imputation with a LGBM Regressor(because it's one of the fastest in performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "LN7R4sNNGlG7",
    "outputId": "c1796817-5d91-4298-8fb5-be0a4ec67ff9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.74321604, 3.78516435, 3.79771682])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = lgb.LGBMRegressor(verbose=2)\n",
    "mean_imputed_score = cross_val_score(\n",
    "        lgbm, mean_imputed_df, y_target, scoring=root_mean_squared_error,\n",
    "        cv=3,verbose = 2,n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vw3VIZpfO9S"
   },
   "outputs": [],
   "source": [
    "## Sorry but I forgot to save it \n",
    "## So creating a list to use it for later purposes\n",
    "mean_imputed_score = [3.74321604, 3.78516435, 3.79771682]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbroebeFM1xg"
   },
   "source": [
    "<a id=\"model_based_imputation\"></a>\n",
    "## 5. Model based Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "viNeL5tkAq9e",
    "outputId": "9451c13f-b202-467c-fe16-d7bfab14939f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame to be filled :  (201917, 181)\n"
     ]
    }
   ],
   "source": [
    "## Features to be considered for imputation : All of the features containing null values\n",
    "impute_feat = list(mean_impute_feat) + list(model_impute_feat)\n",
    "X_features = X_features[impute_feat]\n",
    "print(\"Shape of the DataFrame to be filled : \",X_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-cFRxvFofbrb"
   },
   "source": [
    "### 5.1 DecisionTree based Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "id": "iJ519kJqGobn",
    "outputId": "2212c1b8-436b-46a9-d1f2-93c391626af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Decision Tree Regressor...\n",
      "Creating Iterative Imputer...\n",
      "Imputing features...\n",
      "[IterativeImputer] Completing matrix with shape (201917, 181)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 288.80\n",
      "[IterativeImputer] Change: 2951076040.948445, scaled tolerance: 400000025.6 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 577.59\n",
      "[IterativeImputer] Change: 2926519621.044958, scaled tolerance: 400000025.6 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 868.37\n",
      "[IterativeImputer] Change: 990947741.1861651, scaled tolerance: 400000025.6 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 1159.60\n",
      "[IterativeImputer] Change: 5334464659.990709, scaled tolerance: 400000025.6 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 1451.19\n",
      "[IterativeImputer] Change: 5391873328.865762, scaled tolerance: 400000025.6 \n",
      "[IterativeImputer] Change: 666727572.8470494, scaled tolerance: 400000025.6 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 2032.46\n",
      "[IterativeImputer] Change: 214360068.02152002, scaled tolerance: 400000025.6 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Decision Tree Regressor...\")\n",
    "dt_regressor = DecisionTreeRegressor(max_features='sqrt',\n",
    "                                     max_depth=5,\n",
    "                                     random_state=0)\n",
    "print(\"Creating Iterative Imputer...\")\n",
    "iterative_imputer = IterativeImputer(random_state = 0,\n",
    "                                     estimator = dt_regressor,\n",
    "                                     tol = 0.1,\n",
    "                                     verbose=30)\n",
    "print(\"Imputing features...\")\n",
    "dt_imputed_features = iterative_imputer.fit_transform(X_features)\n",
    "dt_imputed_df = pd.DataFrame(dt_imputed_features,columns=X_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZo9zZhofxkw"
   },
   "source": [
    "### 5.1.1 Dumping the dataframe imputed by Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZBETLEyR4Lz"
   },
   "outputs": [],
   "source": [
    "pickle.dump(dt_imputed_df,open('gdrive/My Drive/ColabNotebooks/dt_imputed_df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4qcvo9_iauE"
   },
   "outputs": [],
   "source": [
    "dt_imputed_df = pickle.load(open('gdrive/My Drive/ColabNotebooks/dt_imputed_df.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjAPs7BDf1Ci"
   },
   "source": [
    "### 5.1.2 Estimating the performance of the imputed_df using LGBMRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "pilNPvuvhUu3",
    "outputId": "b32a4d8d-2cdf-4250-a2af-b3ff9c577b60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 458)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imputed_df = pd.concat([X_train[nnull_impute_feat],dt_imputed_df],axis=1)\n",
    "model_imputed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "CLRPEdTWOx3Q",
    "outputId": "668bbb9f-50e0-404f-e6b3-68b1a106659b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.73713822, 3.7875392 , 3.78328342])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_estimator = lgb.LGBMRegressor(verbose=10)\n",
    "cross_val_score(\n",
    "        lgbm_estimator,model_imputed_df, y_target,\n",
    "        scoring=root_mean_squared_error,\n",
    "        cv=3,verbose = 20,n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0pEp5aug6Hw"
   },
   "outputs": [],
   "source": [
    "dt_imputed_score = [3.73713822, 3.7875392 , 3.78328342]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DKKGat_MNX2x"
   },
   "source": [
    "<a id=\"mixed_imputation\"></a>\n",
    "### 6. Mixed Imputation\n",
    "* Close the notebook and restart again to run below cells of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCC0xm6LNSFV"
   },
   "outputs": [],
   "source": [
    "simple_imputed_df = simpleImputerForAllCategories(X_features[mean_impute_feat])\n",
    "print(\"Shape of Mean Imputed features : \",simple_imputed_df.shape)\n",
    "\n",
    "print(\"***************Creating Extra Trees Regressor*****************\")\n",
    "et_regressor = ExtraTreesRegressor( n_estimators=10,\n",
    "                                    verbose=10)\n",
    "print(\"***************Creating Iterative Imputer*********************\")\n",
    "tree_based_imputer = IterativeImputer(estimator = et_regressor,\n",
    "                                      max_iter = 3,\n",
    "                                      verbose = 20)\n",
    "print(\"***************Imputing features******************************\")\n",
    "tree_imputed_df = tree_based_imputer.fit_transform(X_features[model_impute_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0DONCwt_j3b"
   },
   "outputs": [],
   "source": [
    "tree_imputed_df = pd.DataFrame(tree_imputed_df,columns = model_impute_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "PaIiBS1qg8W_",
    "outputId": "5b395e4d-b573-4362-e4aa-4c8f01bf3cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Creating not null dataframe********************\n",
      "***************Concatenating dataframes***********************\n",
      "Mixed Imputed Dataframe shape :  (201917, 458)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_2_bin</th>\n",
       "      <th>feature_1_bin</th>\n",
       "      <th>first_active_day</th>\n",
       "      <th>first_active_wday</th>\n",
       "      <th>first_active_mm</th>\n",
       "      <th>first_active_year</th>\n",
       "      <th>category_4_nunique</th>\n",
       "      <th>most_recent_sales_range_nunique</th>\n",
       "      <th>most_recent_purchases_range_nunique</th>\n",
       "      <th>numerical_1_min</th>\n",
       "      <th>numerical_1_max</th>\n",
       "      <th>numerical_1_median</th>\n",
       "      <th>numerical_1_sum</th>\n",
       "      <th>numerical_1_std</th>\n",
       "      <th>numerical_2_min</th>\n",
       "      <th>numerical_2_max</th>\n",
       "      <th>numerical_2_median</th>\n",
       "      <th>numerical_2_sum</th>\n",
       "      <th>numerical_2_std</th>\n",
       "      <th>avg_sales_lag3_min</th>\n",
       "      <th>avg_sales_lag3_max</th>\n",
       "      <th>avg_sales_lag3_median</th>\n",
       "      <th>avg_sales_lag3_sum</th>\n",
       "      <th>avg_sales_lag3_std</th>\n",
       "      <th>avg_sales_lag6_min</th>\n",
       "      <th>avg_sales_lag6_max</th>\n",
       "      <th>avg_sales_lag6_median</th>\n",
       "      <th>avg_sales_lag6_sum</th>\n",
       "      <th>avg_sales_lag6_std</th>\n",
       "      <th>avg_sales_lag12_min</th>\n",
       "      <th>avg_sales_lag12_max</th>\n",
       "      <th>avg_sales_lag12_median</th>\n",
       "      <th>avg_sales_lag12_sum</th>\n",
       "      <th>avg_sales_lag12_std</th>\n",
       "      <th>avg_purchases_lag3_min</th>\n",
       "      <th>avg_purchases_lag3_median</th>\n",
       "      <th>avg_purchases_lag6_min</th>\n",
       "      <th>...</th>\n",
       "      <th>np_amount_mean_6_8</th>\n",
       "      <th>np_amount_sum_5_7</th>\n",
       "      <th>np_amount_sum_6_8</th>\n",
       "      <th>np_amount_std_3_5</th>\n",
       "      <th>np_amount_std_4_6</th>\n",
       "      <th>np_amount_std_5_7</th>\n",
       "      <th>np_amount_min_9</th>\n",
       "      <th>np_amount_min_8</th>\n",
       "      <th>np_amount_min_7</th>\n",
       "      <th>np_amount_max_9</th>\n",
       "      <th>np_amount_max_8</th>\n",
       "      <th>np_amount_max_7</th>\n",
       "      <th>np_amount_mean_9</th>\n",
       "      <th>np_amount_mean_8</th>\n",
       "      <th>np_amount_mean_7</th>\n",
       "      <th>np_amount_sum_9</th>\n",
       "      <th>np_amount_sum_8</th>\n",
       "      <th>np_amount_sum_7</th>\n",
       "      <th>np_amount_std_8</th>\n",
       "      <th>np_amount_std_7</th>\n",
       "      <th>np_amount_std_6</th>\n",
       "      <th>np_amount_min_6_7</th>\n",
       "      <th>np_amount_min_7_8</th>\n",
       "      <th>np_amount_max_6_7</th>\n",
       "      <th>np_amount_max_7_8</th>\n",
       "      <th>np_amount_mean_6_7</th>\n",
       "      <th>np_amount_mean_7_8</th>\n",
       "      <th>np_amount_sum_6_7</th>\n",
       "      <th>np_amount_sum_7_8</th>\n",
       "      <th>np_amount_std_4_5</th>\n",
       "      <th>np_amount_std_5_6</th>\n",
       "      <th>np_amount_std_6_7</th>\n",
       "      <th>install_3_min</th>\n",
       "      <th>install_3_max</th>\n",
       "      <th>install_3_mean</th>\n",
       "      <th>install_3_sum</th>\n",
       "      <th>install_2_min</th>\n",
       "      <th>install_2_max</th>\n",
       "      <th>install_2_mean</th>\n",
       "      <th>install_2_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>172.719653</td>\n",
       "      <td>-0.017811</td>\n",
       "      <td>4054.082784</td>\n",
       "      <td>43.845096</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>170.736672</td>\n",
       "      <td>-0.027726</td>\n",
       "      <td>3905.022112</td>\n",
       "      <td>43.376015</td>\n",
       "      <td>0.71</td>\n",
       "      <td>7.73</td>\n",
       "      <td>1.00</td>\n",
       "      <td>326.47</td>\n",
       "      <td>1.071570</td>\n",
       "      <td>0.58</td>\n",
       "      <td>147.69</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1878.67</td>\n",
       "      <td>29.123759</td>\n",
       "      <td>0.53</td>\n",
       "      <td>194.61</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2146.41</td>\n",
       "      <td>34.015704</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.008886</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757208</td>\n",
       "      <td>0.570880</td>\n",
       "      <td>11.105721</td>\n",
       "      <td>1.112179</td>\n",
       "      <td>2.412530</td>\n",
       "      <td>0.894544</td>\n",
       "      <td>140.449005</td>\n",
       "      <td>24.209999</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2284.621094</td>\n",
       "      <td>51.610001</td>\n",
       "      <td>292.600006</td>\n",
       "      <td>853.007263</td>\n",
       "      <td>37.583332</td>\n",
       "      <td>51.224491</td>\n",
       "      <td>6109.254883</td>\n",
       "      <td>112.750000</td>\n",
       "      <td>2510.000000</td>\n",
       "      <td>13.711679</td>\n",
       "      <td>57.591129</td>\n",
       "      <td>23.332657</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.413052</td>\n",
       "      <td>0.346548</td>\n",
       "      <td>5.669444</td>\n",
       "      <td>0.555563</td>\n",
       "      <td>1.362958</td>\n",
       "      <td>0.498873</td>\n",
       "      <td>22.261641</td>\n",
       "      <td>1.092646</td>\n",
       "      <td>2.207970</td>\n",
       "      <td>0.405143</td>\n",
       "      <td>172.070007</td>\n",
       "      <td>838.057007</td>\n",
       "      <td>469.805481</td>\n",
       "      <td>3158.994873</td>\n",
       "      <td>122.046997</td>\n",
       "      <td>474.470001</td>\n",
       "      <td>263.523956</td>\n",
       "      <td>1964.744995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>172.719653</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>9955.548697</td>\n",
       "      <td>50.528439</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>170.736672</td>\n",
       "      <td>-0.027726</td>\n",
       "      <td>9747.395195</td>\n",
       "      <td>50.070917</td>\n",
       "      <td>0.48</td>\n",
       "      <td>10.75</td>\n",
       "      <td>1.06</td>\n",
       "      <td>446.58</td>\n",
       "      <td>1.073557</td>\n",
       "      <td>0.36</td>\n",
       "      <td>147.69</td>\n",
       "      <td>1.07</td>\n",
       "      <td>754.88</td>\n",
       "      <td>10.913832</td>\n",
       "      <td>0.27</td>\n",
       "      <td>166.68</td>\n",
       "      <td>1.07</td>\n",
       "      <td>811.35</td>\n",
       "      <td>12.332267</td>\n",
       "      <td>0.523977</td>\n",
       "      <td>1.065682</td>\n",
       "      <td>0.307888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706732</td>\n",
       "      <td>0.882258</td>\n",
       "      <td>2.308658</td>\n",
       "      <td>0.327485</td>\n",
       "      <td>2.124190</td>\n",
       "      <td>2.221075</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>548.890015</td>\n",
       "      <td>672.289978</td>\n",
       "      <td>350.429993</td>\n",
       "      <td>113.933334</td>\n",
       "      <td>95.318001</td>\n",
       "      <td>55.814705</td>\n",
       "      <td>2050.800049</td>\n",
       "      <td>1429.770020</td>\n",
       "      <td>1897.699951</td>\n",
       "      <td>196.520767</td>\n",
       "      <td>85.486519</td>\n",
       "      <td>184.342117</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.587592</td>\n",
       "      <td>0.521248</td>\n",
       "      <td>1.206927</td>\n",
       "      <td>0.585563</td>\n",
       "      <td>1.739395</td>\n",
       "      <td>1.327276</td>\n",
       "      <td>2.062325</td>\n",
       "      <td>1.029998</td>\n",
       "      <td>2.156388</td>\n",
       "      <td>85.269997</td>\n",
       "      <td>721.070007</td>\n",
       "      <td>228.692001</td>\n",
       "      <td>6860.759766</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>3578.479980</td>\n",
       "      <td>311.580475</td>\n",
       "      <td>6543.189941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>21.834638</td>\n",
       "      <td>0.150742</td>\n",
       "      <td>53.787948</td>\n",
       "      <td>4.530581</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>21.596680</td>\n",
       "      <td>-0.047556</td>\n",
       "      <td>46.093982</td>\n",
       "      <td>4.530719</td>\n",
       "      <td>0.93</td>\n",
       "      <td>6.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>50.03</td>\n",
       "      <td>0.894221</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8.42</td>\n",
       "      <td>1.01</td>\n",
       "      <td>51.90</td>\n",
       "      <td>1.118019</td>\n",
       "      <td>0.76</td>\n",
       "      <td>8.57</td>\n",
       "      <td>1.02</td>\n",
       "      <td>52.61</td>\n",
       "      <td>1.140074</td>\n",
       "      <td>0.949288</td>\n",
       "      <td>1.007511</td>\n",
       "      <td>0.871214</td>\n",
       "      <td>...</td>\n",
       "      <td>18.769751</td>\n",
       "      <td>0.449834</td>\n",
       "      <td>33.040489</td>\n",
       "      <td>1.178674</td>\n",
       "      <td>1.573263</td>\n",
       "      <td>0.739397</td>\n",
       "      <td>20.930000</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>22.910000</td>\n",
       "      <td>61.709999</td>\n",
       "      <td>1229.850952</td>\n",
       "      <td>43.470001</td>\n",
       "      <td>39.684998</td>\n",
       "      <td>204.170654</td>\n",
       "      <td>33.190002</td>\n",
       "      <td>158.739990</td>\n",
       "      <td>2351.734863</td>\n",
       "      <td>66.380005</td>\n",
       "      <td>343.415466</td>\n",
       "      <td>14.538116</td>\n",
       "      <td>10.168196</td>\n",
       "      <td>1.243125</td>\n",
       "      <td>8.813312</td>\n",
       "      <td>0.985967</td>\n",
       "      <td>20.214108</td>\n",
       "      <td>1.074721</td>\n",
       "      <td>14.935040</td>\n",
       "      <td>1.074721</td>\n",
       "      <td>35.041737</td>\n",
       "      <td>0.739724</td>\n",
       "      <td>1.301423</td>\n",
       "      <td>0.699416</td>\n",
       "      <td>175.071991</td>\n",
       "      <td>812.362000</td>\n",
       "      <td>432.269684</td>\n",
       "      <td>1902.229004</td>\n",
       "      <td>115.140999</td>\n",
       "      <td>417.588989</td>\n",
       "      <td>232.108154</td>\n",
       "      <td>934.786011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>27.575368</td>\n",
       "      <td>-0.047556</td>\n",
       "      <td>367.021217</td>\n",
       "      <td>8.862527</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>27.317580</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>359.416486</td>\n",
       "      <td>8.776750</td>\n",
       "      <td>0.59</td>\n",
       "      <td>6.93</td>\n",
       "      <td>1.03</td>\n",
       "      <td>143.23</td>\n",
       "      <td>1.800569</td>\n",
       "      <td>0.42</td>\n",
       "      <td>8.42</td>\n",
       "      <td>1.05</td>\n",
       "      <td>155.27</td>\n",
       "      <td>2.258579</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8.57</td>\n",
       "      <td>1.05</td>\n",
       "      <td>156.16</td>\n",
       "      <td>2.309363</td>\n",
       "      <td>0.617886</td>\n",
       "      <td>1.042628</td>\n",
       "      <td>0.426152</td>\n",
       "      <td>...</td>\n",
       "      <td>20.932686</td>\n",
       "      <td>131.459976</td>\n",
       "      <td>28.197517</td>\n",
       "      <td>20.601368</td>\n",
       "      <td>3.179530</td>\n",
       "      <td>106.546356</td>\n",
       "      <td>220.272995</td>\n",
       "      <td>9.923000</td>\n",
       "      <td>396.557007</td>\n",
       "      <td>2447.837891</td>\n",
       "      <td>1218.710938</td>\n",
       "      <td>3523.053955</td>\n",
       "      <td>1188.185669</td>\n",
       "      <td>290.205658</td>\n",
       "      <td>1795.645508</td>\n",
       "      <td>3954.260986</td>\n",
       "      <td>2942.333008</td>\n",
       "      <td>7753.904785</td>\n",
       "      <td>439.337128</td>\n",
       "      <td>1755.611084</td>\n",
       "      <td>182.882996</td>\n",
       "      <td>155.404449</td>\n",
       "      <td>131.492538</td>\n",
       "      <td>10.998015</td>\n",
       "      <td>27.488863</td>\n",
       "      <td>13.718294</td>\n",
       "      <td>18.909939</td>\n",
       "      <td>13.671411</td>\n",
       "      <td>96.939667</td>\n",
       "      <td>2.173726</td>\n",
       "      <td>10.640070</td>\n",
       "      <td>16.172998</td>\n",
       "      <td>134.509995</td>\n",
       "      <td>325.589996</td>\n",
       "      <td>255.345001</td>\n",
       "      <td>1021.380005</td>\n",
       "      <td>117.320000</td>\n",
       "      <td>187.889999</td>\n",
       "      <td>141.636658</td>\n",
       "      <td>424.910004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>27.575368</td>\n",
       "      <td>-0.047556</td>\n",
       "      <td>454.585565</td>\n",
       "      <td>8.609387</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>27.317580</td>\n",
       "      <td>-0.047556</td>\n",
       "      <td>447.367514</td>\n",
       "      <td>8.532154</td>\n",
       "      <td>0.51</td>\n",
       "      <td>6.93</td>\n",
       "      <td>1.08</td>\n",
       "      <td>199.62</td>\n",
       "      <td>1.401889</td>\n",
       "      <td>0.62</td>\n",
       "      <td>147.69</td>\n",
       "      <td>1.04</td>\n",
       "      <td>360.51</td>\n",
       "      <td>12.443422</td>\n",
       "      <td>0.44</td>\n",
       "      <td>166.68</td>\n",
       "      <td>1.02</td>\n",
       "      <td>385.18</td>\n",
       "      <td>14.032214</td>\n",
       "      <td>0.392713</td>\n",
       "      <td>1.103070</td>\n",
       "      <td>0.294197</td>\n",
       "      <td>...</td>\n",
       "      <td>20.426350</td>\n",
       "      <td>172.941132</td>\n",
       "      <td>46.274590</td>\n",
       "      <td>23.807180</td>\n",
       "      <td>34.509159</td>\n",
       "      <td>116.786736</td>\n",
       "      <td>294.473999</td>\n",
       "      <td>20.097000</td>\n",
       "      <td>355.397980</td>\n",
       "      <td>2575.458984</td>\n",
       "      <td>1153.218018</td>\n",
       "      <td>3753.913086</td>\n",
       "      <td>1318.838379</td>\n",
       "      <td>442.876404</td>\n",
       "      <td>1754.358154</td>\n",
       "      <td>4408.523926</td>\n",
       "      <td>2756.826904</td>\n",
       "      <td>7616.937988</td>\n",
       "      <td>504.852722</td>\n",
       "      <td>1840.619995</td>\n",
       "      <td>287.958008</td>\n",
       "      <td>1370.781616</td>\n",
       "      <td>170.390823</td>\n",
       "      <td>10.953004</td>\n",
       "      <td>26.873693</td>\n",
       "      <td>13.554404</td>\n",
       "      <td>17.225767</td>\n",
       "      <td>14.984738</td>\n",
       "      <td>78.082375</td>\n",
       "      <td>30.000162</td>\n",
       "      <td>21.896540</td>\n",
       "      <td>19.772945</td>\n",
       "      <td>593.960022</td>\n",
       "      <td>1952.459961</td>\n",
       "      <td>1273.209961</td>\n",
       "      <td>2546.419922</td>\n",
       "      <td>127.290001</td>\n",
       "      <td>127.290001</td>\n",
       "      <td>127.290001</td>\n",
       "      <td>127.290001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 458 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  ...  install_2_mean  install_2_sum\n",
       "0          5          2  ...      263.523956    1964.744995\n",
       "1          4          1  ...      311.580475    6543.189941\n",
       "2          2          2  ...      232.108154     934.786011\n",
       "3          4          3  ...      141.636658     424.910004\n",
       "4          1          3  ...      127.290001     127.290001\n",
       "\n",
       "[5 rows x 458 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"***************Creating not null dataframe********************\")\n",
    "nnull_imputed_df = X_features[nnull_impute_feat].copy()\n",
    "\n",
    "print(\"***************Concatenating dataframes***********************\")\n",
    "mixed_imputed_df = pd.concat([nnull_imputed_df,simple_imputed_df,tree_imputed_df],axis=1)\n",
    "print(\"Mixed Imputed Dataframe shape : \",mixed_imputed_df.shape)\n",
    "mixed_imputed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0iVo9uJyiGC"
   },
   "source": [
    "### 6.2 Dumping Mixed Imputed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHtd72H8ATF8"
   },
   "outputs": [],
   "source": [
    "pickle.dump(mixed_imputed_df,open('gdrive/My Drive/ColabNotebooks/mixed_imputed_df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0vgT5XihHU2"
   },
   "outputs": [],
   "source": [
    "mixed_imputed_df = pickle.load(open('gdrive/My Drive/ColabNotebooks/mixed_imputed_df.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5Wrj-5tzjwd"
   },
   "source": [
    "### 6.3 Estimating imputation using LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvYGYnruV65S"
   },
   "outputs": [],
   "source": [
    "lgb_regressor = lgb.LGBMRegressor()\n",
    "mixed_imputed_cv_score = cross_val_score(lgb_regressor,\n",
    "                mixed_imputed_df, y_target,\n",
    "                scoring=root_mean_squared_error,\n",
    "                cv=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uBDoGuIR_tx-",
    "outputId": "a91c216a-46ff-437d-c398-fe3a61c9f0af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.74887711, 3.79043287, 3.79071951])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_imputed_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GXkWyyOT0Y95"
   },
   "source": [
    "<a id=\"comparing_performances\"></a>\n",
    "## 7. Comparing performance of the imputed dataframe using various methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "ypSc3jGWh4hF",
    "outputId": "565f2623-e16b-48dc-94e3-9aaae709ed93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_imputed_score</th>\n",
       "      <td>3.743216</td>\n",
       "      <td>3.785164</td>\n",
       "      <td>3.797717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt_imputed_score</th>\n",
       "      <td>3.737138</td>\n",
       "      <td>3.787539</td>\n",
       "      <td>3.783283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixed_imputed_score</th>\n",
       "      <td>3.748877</td>\n",
       "      <td>3.790433</td>\n",
       "      <td>3.790720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2\n",
       "mean_imputed_score   3.743216  3.785164  3.797717\n",
       "dt_imputed_score     3.737138  3.787539  3.783283\n",
       "mixed_imputed_score  3.748877  3.790433  3.790720"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputation_cv_scores = pd.DataFrame({'mean_imputed_score' : mean_imputed_score,\n",
    "                         'dt_imputed_score' : dt_imputed_score,\n",
    "                         'mixed_imputed_score' : mixed_imputed_cv_score}).T\n",
    "imputation_cv_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "qfkPR894iU6j",
    "outputId": "5f3bef2a-f886-4950-ccf0-41ffcada6b10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_imputed_score</th>\n",
       "      <td>3.743216</td>\n",
       "      <td>3.785164</td>\n",
       "      <td>3.797717</td>\n",
       "      <td>3.775366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt_imputed_score</th>\n",
       "      <td>3.737138</td>\n",
       "      <td>3.787539</td>\n",
       "      <td>3.783283</td>\n",
       "      <td>3.769320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixed_imputed_score</th>\n",
       "      <td>3.748877</td>\n",
       "      <td>3.790433</td>\n",
       "      <td>3.790720</td>\n",
       "      <td>3.776676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2  avg_score\n",
       "mean_imputed_score   3.743216  3.785164  3.797717   3.775366\n",
       "dt_imputed_score     3.737138  3.787539  3.783283   3.769320\n",
       "mixed_imputed_score  3.748877  3.790433  3.790720   3.776676"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputation_cv_scores['avg_score'] = imputation_cv_scores.apply(lambda x : np.sum(x)/len(x),axis=1)\n",
    "imputation_cv_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "5efV-gBMi_V8",
    "outputId": "94936597-47f0-4c3e-e930-c6353d1ff196"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_imputed_score</td>\n",
       "      <td>3.743216</td>\n",
       "      <td>3.785164</td>\n",
       "      <td>3.797717</td>\n",
       "      <td>3.775366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt_imputed_score</td>\n",
       "      <td>3.737138</td>\n",
       "      <td>3.787539</td>\n",
       "      <td>3.783283</td>\n",
       "      <td>3.769320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mixed_imputed_score</td>\n",
       "      <td>3.748877</td>\n",
       "      <td>3.790433</td>\n",
       "      <td>3.790720</td>\n",
       "      <td>3.776676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index         0         1         2  avg_score\n",
       "0   mean_imputed_score  3.743216  3.785164  3.797717   3.775366\n",
       "1     dt_imputed_score  3.737138  3.787539  3.783283   3.769320\n",
       "2  mixed_imputed_score  3.748877  3.790433  3.790720   3.776676"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputation_cv_scores = imputation_cv_scores.reset_index()\n",
    "imputation_cv_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "uT479k1GjcvN",
    "outputId": "db72a0b0-113c-4fe0-8d9e-5a5753658157"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>norm_avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_imputed_score</td>\n",
       "      <td>3.743216</td>\n",
       "      <td>3.785164</td>\n",
       "      <td>3.797717</td>\n",
       "      <td>3.775366</td>\n",
       "      <td>0.821816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt_imputed_score</td>\n",
       "      <td>3.737138</td>\n",
       "      <td>3.787539</td>\n",
       "      <td>3.783283</td>\n",
       "      <td>3.769320</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mixed_imputed_score</td>\n",
       "      <td>3.748877</td>\n",
       "      <td>3.790433</td>\n",
       "      <td>3.790720</td>\n",
       "      <td>3.776676</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index         0         1         2  avg_score  norm_avg_score\n",
       "0   mean_imputed_score  3.743216  3.785164  3.797717   3.775366        0.821816\n",
       "1     dt_imputed_score  3.737138  3.787539  3.783283   3.769320        0.000000\n",
       "2  mixed_imputed_score  3.748877  3.790433  3.790720   3.776676        1.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "norm_avg_score = min_max_scaler.fit_transform(imputation_cv_scores[['avg_score']])\n",
    "imputation_cv_scores['norm_avg_score'] = norm_avg_score\n",
    "imputation_cv_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "gFg3p2C5kHFz",
    "outputId": "d7f1b65b-5820-4736-8385-34ddf2c9eb2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f12e25b2f98>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot('index','norm_avg_score',data = imputation_cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zZwup-zZknmR"
   },
   "source": [
    "<a id=\"final_analysis\"></a>\n",
    "### Analysis\n",
    "* It can be observed that the RMSE value is minimum for Decision Tree imputed Dataframe.\n",
    "* We didn't go for any hyper-parameter tuning.\n",
    "* Also we couldn't try much of Iterative Imputation because of RAM issues in google Colab as well as my personal desktop.\n",
    "* After several days of finding out which parameters could actually decrease the RAM usage we were able to run some decent experiments on imputation.\n",
    "* There are two set of parameters to control\n",
    "  * Hyper-parameters of the model which is going to impute the dataframe.\n",
    "  * Hyper-paramters of the Iterative and Simple Imputer which have parameters like max_iteration and tolerance.\n",
    "  * If the imputation converges before the max_iteration then well and good otherwise it uses up the entire RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebuIdb59mQIo"
   },
   "source": [
    "## 8. Imputing columns for new merchant transactions based on our observations above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_new_df = pickle.load(open('trans_new_df.pkl','rb'))\n",
    "impute_new_trans_col = pickle.load(open('selected_cols_from_new_trans.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Using Decision Tree based imputer\n",
    "* Since it performed better than all the remaining imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Decision Tree Regressor...\n",
      "Creating Iterative Imputer...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Decision Tree Regressor...\")\n",
    "dt_regressor = DecisionTreeRegressor(max_features='sqrt',\n",
    "                                     max_depth=5,\n",
    "                                     random_state=0)\n",
    "print(\"Creating Iterative Imputer...\")\n",
    "iterative_imputer = IterativeImputer(random_state = 0,\n",
    "                                     estimator = dt_regressor,\n",
    "                                     tol = 0.1,\n",
    "                                     verbose=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2  Dropping the unnecessary columns\n",
    "* Dropping card_id and categorical mode features since they are useless for modelling\n",
    "* Converting boolean features into 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trans_new_df[impute_new_trans_col]\n",
    "X_features = X_train.drop(['card_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns :  Index(['category_1_mode', 'category_3_mode'], dtype='object')\n",
      "Boolean columns :  Index(['is_purchase_month_end_mode', 'is_purchase_month_end_min',\n",
      "       'is_purchase_month_start_mode', 'is_purchase_month_start_min',\n",
      "       'is_purchase_quarter_start_mode', 'is_purchase_quarter_start_min',\n",
      "       'is_purchase_quarter_end_mode', 'is_purchase_quarter_end_min',\n",
      "       'is_purchase_year_end_mode', 'is_purchase_year_end_min',\n",
      "       'is_purchase_year_start_mode', 'is_purchase_year_start_min',\n",
      "       'is_christmas_mode', 'is_christmas_min', 'is_mothers_day_mode',\n",
      "       'is_mothers_day_min', 'is_childrens_day_mode', 'is_childrens_day_min',\n",
      "       'is_valentines_day_mode', 'is_valentines_day_min',\n",
      "       'is_fathers_day_mode', 'is_fathers_day_min'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_cols = X_features.select_dtypes('O').columns.unique()\n",
    "bool_cols = X_features.select_dtypes('bool').columns.unique()\n",
    "print(\"Categorical columns : \",cat_cols)\n",
    "print(\"Boolean columns : \",bool_cols)\n",
    "\n",
    "## Mode features are useless\n",
    "X_features.drop(cat_cols,axis=1,inplace=True)\n",
    "\n",
    "## for boolean features converting them into 1's and 0's\n",
    "for col in bool_cols:\n",
    "    X_features[col] = X_features[col].apply(lambda x : 1 if True else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 replacing infinity values by nan's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features.replace([np.inf,-np.inf],np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing features...\n",
      "[IterativeImputer] Completing matrix with shape (179986, 199)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 480.26\n",
      "[IterativeImputer] Change: 6820.386680822434, scaled tolerance: 843.2 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 967.46\n",
      "[IterativeImputer] Change: 5893.547782301697, scaled tolerance: 843.2 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 1458.23\n",
      "[IterativeImputer] Change: 5448.720516115342, scaled tolerance: 843.2 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 1939.31\n",
      "[IterativeImputer] Change: 4315.096195200879, scaled tolerance: 843.2 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 2432.11\n",
      "[IterativeImputer] Change: 3924.975576559918, scaled tolerance: 843.2 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 2922.11\n",
      "[IterativeImputer] Change: 3179.642601784601, scaled tolerance: 843.2 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 3410.20\n",
      "[IterativeImputer] Change: 3419.9672983087385, scaled tolerance: 843.2 \n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 3921.29\n",
      "[IterativeImputer] Change: 3484.4255219436027, scaled tolerance: 843.2 \n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 4441.00\n",
      "[IterativeImputer] Change: 3405.433650809366, scaled tolerance: 843.2 \n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 4925.31\n",
      "[IterativeImputer] Change: 3837.497097643571, scaled tolerance: 843.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\capiot\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\impute\\_iterative.py:670: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Imputing features...\")\n",
    "dt_imputed_features = iterative_imputer.fit_transform(X_features)\n",
    "dt_imputed_df = pd.DataFrame(dt_imputed_features,columns=X_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Add card_id column and target column\n",
    "* So that we can use it for feature selection purpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179986, 199)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_imputed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179986, 200)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_imputed_df = pd.concat([X_train['card_id'],dt_imputed_df],axis=1)\n",
    "dt_imputed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179986, 201)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_train_df = pickle.load(open('trans_train_df.pkl','rb'))\n",
    "dt_imputed_df = pd.merge(trans_train_df[['card_id','target']],dt_imputed_df,on='card_id',how='inner')\n",
    "dt_imputed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dt_imputed_df,open('feature_set_4.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Feature Imputation for generated features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
